\documentclass[12pt]{article}

\input{setup.tex}

\title{Transplanting Approach}
\date{}

\begin{document}

\maketitle

\section{Setup}

Given a smooth, regular curve \(\gamma \in C^{\infty}(\So \to \RR^2)\) with length \(L(\gamma) = 2\pi\), we define the energy,
\begin{equation}
\label{eq:Egamma}
E(\gamma) = \inf\left\{\int_{\So} \abs{\partial_s f}^2 + \kappa^2 f^2 ds : \int_{\So} f^2 = 1\right\} = \inf\left\{\frac{\int_{\So} \abs{\partial_s f}^2 + \kappa^2 f^2 ds}{\int_{\So} f^2 ds} : f \not\equiv 0\right\}
\end{equation}
where \(f \in C^{\infty}(\So \to \RR^2)\) is assumed smooth.

For a given \(f \in C^{\infty}(\So \to \RR^2)\), let us also write
\begin{equation}
\label{eq:Egammaf}
E(\gamma, f) = \frac{\int_{\So} \abs{\partial_s f}^2 + \kappa^2 f^2 ds}{\int_{\So} f^2 ds}
\end{equation}
so that
\begin{equation}
\label{eq:EgammaEgammaf}
E(\gamma) = \inf\left\{E(\gamma, f) : f \not\equiv 0\right\}.
\end{equation}

Standard arguments imply that the energy is the first eigenvalue of the Euler-Lagrange equation,
\begin{equation}
\label{eq:ELf}
-\partial_s^2 f + \kappa^2 f = 0
\end{equation}
and that infimum is attained by the first eigenfunction \(f\) satisfying \(f > 0\). Therefore, we restrict our attention to \(f > 0\).

Let us write,
\begin{equation}
\label{eq:TN}
T = \gamma', \quad N = -J T
\end{equation}
for the unit tangent and normal. Here we choose the orientation \(N = -JT\) for convenience when dealing with circles later. Define the geodesic curvature \(\kappa\) by the Frenet-Serret formula
\begin{equation}
\label{eq:FS}
\partial_s T = - \kappa N, \quad \partial_s N = \kappa T.
\end{equation}

For any \(\gamma\) and \(f > 0\), define
\begin{equation}
\label{eq:X}
X = X(f, \gamma) = f T.
\end{equation}
Note that we then have \(\forall s \> X(s) \ne 0\) and
\begin{equation}
\label{eq:TNX}
T = \frac{X}{\abs{X}}, \quad f = \abs{X}, N = -J \frac{X}{\abs{X}}
\end{equation}
and we may recover \(\gamma\) and \(f\) from \(X\) (up to rigid motion of \(\gamma\)) by defining,
\begin{equation}
\label{eq:gammaX}
\gamma(s) = \gamma (X) (s) = \int_0^s \frac{X}{\abs{X}} ds, \quad f = \abs{X}.
\end{equation}
Notice that defining the \(\RR^2\)-valued functional,
\begin{equation}
\label{eq:alpha}
\alpha(X) = \int_{\So} \frac{X}{\abs{X}} ds
\end{equation}
we have that the set of \(X = X(\gamma, f)\) with \(f > 0\) satisfies,
\[
\alpha(X) = \int_{\So} T ds = 0.
\]

Since the energy \(E(\gamma, f)\) is invariant under rigid motion of \(\gamma\), using the Frenet-Serret equations \eqref{eq:FS}, we may then express it in terms of \(X\) by,
\begin{equation}
\label{eq:gammafX}
E(\gamma, f) = E(X) = \frac{\int_{\So} \abs{X'}^2 ds}{\int_{\So} \abs{X}^2 ds} = \frac{\|X'\|_2^2}{\|X\|_2^2}.
\end{equation}

Then we have,
\begin{equation}
\label{eq:infimums}
\begin{split}
\lambda = \inf\left\{E(\gamma) : L(\gamma) = 2\pi\right\} &= \inf\left\{E(\gamma, f) : L(\gamma) = 2\pi, f \not\equiv 0\right\} \\
&= \inf\left\{E(X) : \forall s \> X(s) \ne 0, \alpha(X) = 0\right\}.
\end{split}
\end{equation}

For this reason, we call \(\alpha\) the \emph{constraint functional}. We have the following conjecture regarding the least energy for the constrained problem:

\begin{conj}
\label{conj:main}
\[
\lambda = 1.
\]
\end{conj}

As usual, the space of smooth maps is not well suited to the minimisation problem, so we work instead with maps \(X \in H = W^{1,2} (\So \to \RR^2)\) for which energy functional,
\[
E(X) = \frac{\|X'\|_2^2}{\|X\|_2^2}
\]
is well defined for all \(X \ne 0\).

To deal with the constraint functional, \(\alpha\) we note that while \(\alpha\) is not defined on all of \(H\), it is defined at least for the subset
\[
H^0 = \{X \in W^{1,2} (\So \to \RR^2 \backslash \{0\})\}
\]
of maps avoiding the origin. Here to define \(H^0\) we first note that given any fixed vector \(V \in \RR^2\), writing \(\inpr{\cdot}{\cdot}\) for the inner-product on \(\RR^2\), the map
\[
X \in H \mapsto \inpr{X}{V} \in W^{1,2}(\So \to \RR)
\]
is well defined and continuous. Since \(\So\) is one-dimensional, Morrey's inequality with \(n=1,p=2\) gives us a constant \(C > 0\) such that
\[
\|X^i\|_{C^{0,1/2}} \leq C\|X^i\|_{W^{1,2}}.
\]
Then \(X^1 = \inpr{X}{e_1}\) and \(X^2 = \inpr{X}{e_2}\) embed continuously into \(C^0(\So \to \RR), \|\cdot\|_{\infty}\) and hence we obtain a continuous embedding,
\[
\iota : H \to C^0(\So \to \RR^2), \|\cdot\|_{\infty}.
\]
Then we define the open set in \(H\),
\begin{equation}
\label{eq:H0}
H^0 = \iota^{-1}\left(\{X \in C^0(\So \to \RR^2\backslash \{0\})\}\right).
\end{equation}
We also have use for the open sets defined for \(\epsilon > 0\) by,
\begin{equation}
\label{eq:Hepsilon}
H^{\epsilon} = \iota^{-1}\left(\{X \in C^0(\So \to \RR^2\backslash \BB_{\epsilon}(0))\}\right).
\end{equation}

Now we have that \(\alpha\) is a well defined functional on \(H^{\epsilon}\) for \(\epsilon \geq 0\). We then define the constraint sets,
\begin{equation}
\label{eq:constraintsets}
\C = \{X \in H^0 : \alpha(X) = 0\}, \quad \C_{\epsilon} = \{X \in X^{\epsilon} : \alpha(X) = 0\}.
\end{equation}

\begin{lem}
\label{lem:Csubmanifold}
The constraint functional \(\alpha\) is \(C^1\) on the open set \(H^0\).
\end{lem}

\begin{proof}
Given any \(X,V \in H^0\), we first show that the Gateaux derivative \(d\alpha_X (V)\) exists. That is,
\[
\lim_{t\to 0} \frac{\alpha(X + t V) - \alpha(X)}{t} = \partial_t|_{t=0} \alpha(X + tV)
\]
exists. First observe that we may assume \(X, V\) are continuous and that we have \(\abs{X} > 0\). Then the map,
\[
(t, s) \mapsto \beta(X(s) + t V(s)) = \frac{X(s) + t V(s)}{\abs{X(s) + t V(s)}}
\]
is continuous with continuous partial derivative with respect to \(t\) for sufficiently small \(t\) (uniformly in \(\theta\)). Thus by compactness of \(\So\), we may interchange the order of integration and differentiation to obtain that
\[
\begin{split}
d\alpha_X (V) &= \partial_t|_{t=0} \alpha(X + tV) = \int_{\So} \partial_t|_{t=0} \beta (X(s) + tV(s))  ds \\
&= \int_{\So} \frac{1}{\abs{X}}\left(V - \inpr{V}{\frac{X}{\abs{X}}} \frac{X}{\abs{X}}\right) ds
\end{split}
\]
is well defined. In fact recalling that \(T = \tfrac{X}{\abs{X}}, N = -J T\) from equation \eqref{eq:TNX}, we have
\begin{equation}
\label{eq:alphagateaux}
d\alpha_X (V) = \int_{\So} \frac{\pi_N(V)}{\abs{X}} ds
\end{equation}
where
\[
\pi_N (V) (s)= \pi_{N (s)} (V(s)) = \inpr{V(s)}{N(s)}N(s)
\]
denotes the orthogonal (in \(\RR^2\)) projection onto \(N(s)\).

Now we show that \(\alpha\) is in fact Frechet differentiable and \(C^1\). That is,
\[
\lim_{V \to 0} \frac{\|\alpha(X + V) - \alpha(X) - d\alpha_X(V)\|_{\RR^2}}{\|V\|_{W^{1,2}}} = 0
\]
and the map
\[
X \in \C \mapsto d\alpha_X \in \mathcal{B} (H, \RR^2)
\]
is continuous. In fact, by the mean value theorem for Gateaux differentiable functions (see Andrews-Hopper but there must be a more generic ref), it suffices to prove only the latter statement.

Thus we seek to prove that
\[
\lim_{X \underset{H}{\to} X_0} \|d\alpha_X - d\alpha_{X_0}\|_{\mathcal{B}(H, \RR^2)} = \lim_{X \underset{H}{\to} X_0} \sup \{\abs{d\alpha_X (V) - d\alpha_{X_0}(V)} : \|V\|_{W^{1,2}} = 1\} = 0.
\]
Since we have the continuous emebedding \(\iota : H \to C^0\), \(X \underset{H}{\to} X_0\) implies that \(X \underset{C^0}{\to} X_0\) and hence it is sufficient to prove that
\[
\lim_{X \underset{C^0}{\to} X_0} \sup \{\abs{d\alpha_X (V) - d\alpha_{X_0}(V)} : \|V\|_{W^{1,2}} = 1\} = 0.
\]

Now, we have that
\[
\begin{split}
d\alpha_X(V) - d\alpha_{X_0} (V) &= \int_{\So} \frac{\pi_N(V)}{\abs{X}} - \frac{\pi_{N_0} (V)}{\abs{X_0}} ds \\
&= \int_{\So} T(X(s), V(s)) - T(X_0(s), V(s)) ds
\end{split}
\]
where \(T : \RR^2\backslash\{0\} \times \RR^2 \to \RR^2\) is the continuous map
\[
T (x, v) = -\inpr{v}{\frac{1}{\abs{x}^3}J x} x.
\]
Now since \(X_0\) satisfies the constraint, we have \(\abs{X_0} > 0\) and moreover since \(X_0\) is a continuous map on the compact space \(\So\), there exists an \(R, r > 0\) such that for every \(s \in \So\),
\[
r \leq \abs{X_0(s)} \leq R.
\]
Now in the limit \(X \underset{C^0}{\to} X_0\) we may assume that \(\|X - X_0\|_{C^0} < r/2\) so that for every \(s \in \So\),
\[
r/2 \leq \abs{X_0(s)}, \abs{X(s)} \leq R + r/2.
\]
Moreover by Morrey's inequality, for every \(s \in \So\),
\[
\abs{V(s)} \leq \|V\|_{C^0} \leq C \|V\|_{W^{1,2}} \leq C.
\]
Then for all \(s\), \((X(s), V(s) \in \RR^4\) lies in the compact set,
\[
r/2 \leq \abs{x} \leq R + r/2, 0 \leq \abs{v} \leq C
\]
on which the function \(T\) is uniformly continuous.

Thus, independently of \(s \in \So\) and \(V\) with \(\|V\|_{W^{1,2}} = 1\) we have for every \(\epsilon > 0\), there is a \(\delta > 0\) such that
\[
\|X - X_0\|_{C^0} < \delta \Rightarrow \abs{T(X(s), V(s)) - T(X_0(s)) - V(s)} < \epsilon
\]
and hence for every \(V\) such that \(\|V\|_{W^{1,2}} = 1\)
\[
\|X - X_0\|_{C^0} < \delta \Rightarrow \int_{\So} \abs{T(X(s), V(s)) - T(X_0(s)) - V(s)} ds < 2\pi \epsilon
\]
and we obtain the desired continuity.
\end{proof}

\begin{lem}
\label{lem:constraintC1}
\(0\) is a regular value for \(\alpha\) and hence the constraint set \(\C\) is a \(C^1\) sub-manifold of \(H\).
\end{lem}

\begin{proof}
We just need to show that if \(\alpha(X) = 0\), then \(d\alpha : H \to \RR^2\) is surjective. So for each \(v \in \RR^2\) we need a \(V \in H\) such that such that \(d\alpha_X (V) = v\).
\end{proof}

\begin{lem}
\label{lem:lambdaH}
\[
\lambda = \inf\{E(X) : X \in \C\}.
\]
\end{lem}

\begin{proof}
We have
\[
\lambda = \inf\{E(X) : X \in C^{\infty}(\So \to \RR^2) \cap \C\} \geq \inf\{E(X) : X \in \C\}.
\]

On the other hand, since \(C^{\infty}\) is dense in \(H\) and since the constraint set \(\C\) is a submanifold, we have that \(C^{\infty} \cap \C\) is dense in \(\C\) ({\color{red} I think! Take the nearest point projection of a smooth approximator though it's not clear smoothness is ensured}).

Then for any \(X \in \C\) and \(\delta > 0\), there exists a \(Y \in C^{\infty} \cap C\) such that \(\|X - Y\|_{W^{1,2}} < \delta\). But now just observe that \(E\) is continuous away from \(0\) so that given any \(\epsilon > 0\) there exists a \(\delta(\epsilon) > 0\) such that,
\[
\|W - Z\|_{W^{1,2}} < \delta(\epsilon) \Rightarrow E(W) > E(Z) - \epsilon.
\]
Thus for any \(\epsilon > 0\) there is a \(Y \in C^{\infty}\) such that \(\|X - Y\|_{W^{1,2}} < \delta(\epsilon)\) and hence
\[
E(X) > E(Y) - \epsilon \geq \lambda - \epsilon.
\]
Therefore for every \(X \in \C\), \(E(X) \geq \lambda\) and hence
\[
\inf\{E(X) : X \in \C\} \geq \lambda.
\]
\end{proof}

\section{Constraint Preserving Variations}

We know that
\[
d\alpha_X (V) = \int_{\So} \frac{\pi_{\perp} (V)}{|X|} ds.
\]
Defining \(\rho = \inpr{V}{N}\), we may rewrite this as
\[
d\alpha_X (V) = \int_{\So} \frac{\rho N}{|X|} ds.
\]
Working with respect to the angular parameter \(\theta(s)\) determined uniquely by
\[
N(s) = \cos \theta(s) e_1 + \sin \theta(s) e_2 \quad \Rightarrow T(s) = \sin \theta(s) e_1 - \cos \theta(s) e_2,
\]
and satisfying
\[
\partial_s \theta = \kappa \quad \Rightarrow \quad \partial_s = \frac{1}{\kappa} \partial_{\theta}, \quad ds = \kappa d\theta
\]
we have
\[
d\alpha_X (V) = \int_{\So} \bar{\rho} \cos\theta e_1 + \bar{\rho} \sin\theta e_2 d\theta
\]
where
\[
\bar{\rho} = \frac{\rho}{f \kappa}.
\]
This follows from
\[
f = |X|, \quad d\theta = \kappa ds.
\]

Then \(V\) infinitesimally preserves \(\alpha\) if and only if
\[
\bar{\rho} \perp_{L^2} \{\sin, \cos\}
\]
so that
\[
\bar{\rho} = c_0 + \sum_{n\geq 2} a_n \sin(n \theta) + b_n \sin(n \theta).
\]

In other words, the tangent space, \(T_X \C\) to the constraint manifold \(\C\) at \(X\) is given by,
\[
T_X \C = \{\mu T + f\kappa\bar{\rho} N : \mu \text{ arbitrary }, \bar{\rho} \perp_{L^2} \{\sin, \cos\}\}.
\]

For \(\bar{\gamma} = \cos\theta s + \sin \theta s\) a circle, we have \(\bar{\kappa} \equiv 1\) and also eigenfunction, \(f \equiv 1\). Therefore \(\bar{X} = \bar{f} \bar{T}\) is the circle map,
\[
\bar{X}(s) = -\sin\theta e_1 + \cos\theta e_2.
\]
Moreover, \(\theta = s + \text{const}\) and we choose \(\text{const} = 0\) so that \(\theta = s\) and
\[
\bar{N}(\theta) = \cos\theta e_1 + \sin\theta e_2.
\]
Then we also have,
\[
\rho = \bar{\rho}
\]
and arbitrary constraint preserving variations may be written,
\[
V(\theta) = \bar{\mu}(\theta) T(\theta) + \bar{\rho}(\theta) N(\theta) = (- \bar{\mu}\sin\theta + \bar{\rho} \cos\theta) e_1 + (\bar{\mu}\cos\theta + \bar{\rho}\sin\theta) e_2
\]
where \(\bar{\mu} : \So \to \RR\) is arbitrary and \(\bar{\rho} \perp_{L^2} \{\sin, \cos\}\). Hence,
\[
T_{\bar{X}} \C = \{\bar{\mu} T + \bar{\rho} N : \bar{\mu} \text{ arbitrary }, \bar{\rho} \perp_{L^2} \{\sin, \cos\}\}.
\]

\section{Transplanting Variations}

Let \(X\) satisfy the constraint \(\alpha(X) = 0\) (more generally \(X\) is a regular point \(X \in \alpha^{-1} (W)\) for \(W \in \RR^2\) a regular value of \(\alpha\)) and let
\[
\bar{\rho} \perp_{L^2} \{\sin, \cos\}.
\]

Then we may obtain a constraint preserving variation of \(X\) by setting,
\[
V(\theta) = \rho(\theta) N(\theta) = f(\theta) \kappa(\theta) \bar{\rho}(\theta) (\cos\theta e_1 + \sin\theta e_2)
\]
where as in the last section, \(\theta\) is the angular parameter for \(X\).

Now we define for each \(X \in H'\), the transplanting map
\[
\trans_X : T_{\bar{X}} \C \to T_X \C
\]
by
\[
V = \trans_X(\bar{V}) = \bar{\mu}(\theta) T(\theta) + f(\theta)\kappa(\theta)\bar{\rho}(\theta) N(\theta)
\]
where \(\theta\) is the angular parameter for \(X\) and
\[
\bar{\mu} = \inpr{\bar{V}}{\bar{T}}, \bar{\rho} = \inpr{\bar{V}}{\bar{N}}
\]
for
\[
\bar{V} \in T_{\bar{X}} \C.
\]
We may also express this as
\[
(\mu, \rho) = \trans_X(\bar{\mu}, \bar{\rho}) = (\bar{\mu}, f\kappa\bar{\rho})
\]
where
\[
\mu = \inpr{V}{T}, \quad \rho = \inpr{V}{N}.
\]

The transplanting map \(\trans_X\) is an linear isomorphism \(T_{\bar{X}} \C \to T_X \C\).

{\color{red} Is it parallel translation along \(\C\)?}

With respect to the parameter \(s\), we have
\[
V(s) = f(s) \kappa(s) \bar{\rho}(\theta(s)) N(s) = f(s) \kappa(s) \bar{\rho}(\theta(s))(\cos\theta(s) e_1 + \sin\theta(s) e_2).
\]
Thus we may write,
\[
T_X \C = \trans_X(T_{\bar{X}} \C) = \{\mu(s) T(s) + f(s) \kappa(s) \bar{\rho}(\theta(s)) N(s) : \mu \text{ arbitrary }, \bar{\rho} \perp_{L^2} \{\sin, \cos\}\}.
\]

\section{Energy Neutral Variations of Ovals}

{\color{red} This needs to be cleaned up. At the end I also add in horizontal shears. It would be clearer to begin with the motivation and include horizontal shears as well.}

Let
\[
\bar{X} = \cos\theta + \sin \theta
\]
be the circle map. Then the curve
\[
t \mapsto X_t = A(t) \cos\theta e_1 + B(t) \sin \theta e_2
\]
with \(A(0) = B(0) = 1\) and \(A, B > 0\) but otherwise arbitrary, \(X_0 = \bar{X}\) and
\[
E(t) = E(X_t) \equiv 1, \quad \alpha(t) = \alpha(X_t) \equiv 0.
\]

Letting \(a = A'(0), b = B'(0)\), the variation vector at \(t = 0\) is just,
\[
\bar{V} = \partial_t|_{t=0} X_t = a \cos\theta e_1 + b \sin\theta e_2,
\]
and we have
\[
dE_{\bar{X}} (\bar{V}) = 0, \quad d\alpha_{\bar{X}} (\bar{V}) = 0.
\]

In particular, since \(d\alpha_{\bar{X}} (\bar{V}) = 0\), the function
\[
\bar{\rho} (\theta) = \inpr{\bar{V}}{\bar{N}} = \inpr{a \cos\theta e_1 + b \sin\theta e_2}{\cos\theta e_1 + \sin\theta e_2} = a \cos^2\theta + b \sin^2\theta
\]
satisfies \(\bar{\rho} \perp_{L^2} \{\sin, \cos\}\). Of course one can easily verify this directly.

Let us remark that the motivation for these variations is that snce origin centred ellipses are (up to scale) precisely the orbit of the origin centred circle map \(\bar{X}\) under the action of \(\text{SL}_2\), our variations takes \(\bar{X}\) through a family of ellipses which all satisfy the constraint and have the same energy.

Ignoring horizontal shears, they may be written,
\[
X_t = \sqrt{A(t) B(t)}
\begin{pmatrix}
\sqrt{\frac{A(t)}{B(t)}} & 0 \\
0 & \sqrt{\frac{B(t)}{A(t)}}
\end{pmatrix}
\begin{pmatrix}
\cos \theta \\
\sin \theta
\end{pmatrix}.
\]
That is, they are of the form
\[
X_t = \lambda(t) M(t) \cdot \bar{X}
\]
where \(\det M(t) = 1\). So we act by scaling and \(\text{SL}(2)\). Here we don't need every element of \(\text{SL}(2)\): the energy is globally \(O(2)\) invariant with rotations contributing tangential terms to the variation which we already know can be arbitrary. Scaling also does not affect the energy, but allowing scaling means that \(A, B\) can be chosen arbitrarily which makes matters somewhat simpler.

In the Iwasawa decomposition of \(\text{SL}(2)\), we also have horizontal shears,
\[
X_t = 
\begin{pmatrix}
1 & C(t) \\
0 & 1
\end{pmatrix}
\begin{pmatrix}
\cos \theta \\
\sin \theta
\end{pmatrix}
=
\begin{pmatrix}
\cos\theta + C(t) \sin\theta \\
\sin\theta
\end{pmatrix}
\]
with \(C(0) = 0\), giving a variation vector,
\[
\bar{V} = c \sin\theta e_1.
\]
The normal component is
\[
\bar{\rho} = c \cos\theta \sin\theta.
\]
In other words (ignoring the global symmetry given by rotations) we consider variations of the form,
\[
X_t = M(t) N(t) \bar{X}
\]
where \(M\) is diagonal with positive entries, and \(N\) is a horizontal shear satisfying \(M(0) = N(0) = \Id\). The variation vector is then,
\[
\bar{V} = M'(0) N(0) \bar{X} + M(0) N'(0) \bar{X} = a \cos\theta e_1 + b \sin\theta_1 + c \sin\theta e_1
\]
with normal component,
\[
\bar{\rho} = a \cos^2\theta + b \sin^2 \theta + c \cos\theta \sin\theta.
\]

Thus our energy neutral, constraint preserving variations of the circle map \(\bar{X}\) are linear combinations of quadratics \(\cos^2, \sin^2, \cos \sin\).

\section{Energy Decreasing Variations of non-Ovals}

Now we take the constraint preserving, neutral variations, \(\bar{V}\) of circles and transplant them onto constraint preserving, variations \(V = \trans(\bar{V})\) of arbitrary \(X \in H'\). The aim is to show that if \(X\) is not an ellipse, then it is not a critical point with respect to constraint preserving variations. That is, if \(X\) is not an ellipse, there exists a \(V \in T_X \C\) such that
\[
DE_X (V) \ne 0
\]
and hence \(X\) is not a minimiser of the energy.

{\color{red} If this fails, then we move on to the second variation and show that it has negative directions.}

The motivation is that while the conjectured minimisers - the ellipses - are the orbit of circles under \(\text{SL}(2)\), the energy is generally not invariant under the action of \(\text{SL}(2)\). Thus it seems natural to try use these variations to obtain the desired conclusion.

Now, since the energy is scale invariant, we may assume that \(\|X\|_2 = 1\). The variation of energy is then
\[
DE_X (V) = \frac{2}{\|X\|_2^2} \left(\inpr{X'}{V'}_2 - \frac{1}{\|X\|_2^2}\inpr{X}{V}_2\right) = -2 \inpr{X'' + X}{V}_2.
\]

Let us write,
\[
X(s) = x_1(s) e_1 + x_2(s) e_2
\]
so that
\[
X'' + X = (x_1'' + x_1)e_1 + (x_2'' + x_2)e_2.
\]
Expand \(x_1, x_2\) in a Fourier series so that
\[
\begin{split}
X'' + X &= (c_0^1 + \sum_{n\geq 1} a_n^1 (1-n^2)\cos ns + (1-n^2)b_n^1 \sin ns) e_1 \\
&\quad + (c_0^2 + \sum_{n\geq 2} a_n^2 (1-n^2)\cos ns + b_n^2 (1-n^2) \sin ns) e_2.
\end{split}
\]

{\color{red} maybe we should do this with respect to \(\theta\)?}

Now, our variation is,
\[
V(s) = f\kappa\bar{\rho} \cos\theta e_1 + f\kappa\bar{\rho} \sin\theta e_2
\]
where we must keep in mind that
\[
\theta = \theta(s), \quad \bar{\rho} = \bar{\rho}(\theta(s)).
\]

Then,
\[
dE_X (V) = -2 \int_{\So} f\kappa\bar{\rho} \left[\cos\theta (x_1'' + x_1) + \sin\theta (x_2'' + x_2) \right] ds.
\]
It's tempting here to observe the term \(\kappa ds = d\theta\), but then we must also account for \(\partial_s = \kappa \partial_{\theta}\) giving
\[
x_i'' = \kappa \partial_{\theta} (\kappa \partial_\theta x_i) = \kappa^2 \partial_{\theta}^2 x_i + \frac{1}{2} \partial_{\theta} \kappa^2 \partial_{\theta} x_i.
\]
Then in terms of the angular parameter, we have,
\[
dE_X (V) = -2 \int_{\So} f \bar{\rho} \left[\cos\theta (\kappa^2 x_1'' + \kappa\kappa' x_1 ' + x_1) + \sin\theta (\kappa^2 x_2'' + \kappa\kappa' x_2 ' + x_2) \right] d\theta.
\]

Now we show that unless \(X'' + X = 0\), choosing \(\bar{\rho}\) to be a linear combination of \(\cos^2\theta(s), \sin^2\theta(s), \cos\theta(s)\sin\theta(s)\) gives a variation that decreases energy.

Explicitly,
\begin{align*}
dE_X (V) &= -2 \int_{\So} f\kappa\left[a \cos^2\theta + b \sin^2\theta + c \cos\theta \sin\theta\right] & \left[(x_1'' + x_1) \cos\theta + (x_2'' + x_2) \sin\theta \right] & ds \\
&= -2 \int_{\So} f\left[a \cos^2\theta + b \sin^2\theta + c \cos\theta \sin\theta\right] & \big[(\kappa^2 x_1'' + \kappa\kappa' x_1 ' + x_1) \cos\theta & \\
&\quad & + (\kappa^2 x_2'' + \kappa\kappa' x_2 ' + x_2) \sin\theta \big] & d\theta.
\end{align*}

{\color{red} Next perhaps we can expand \(f\kappa\) in a Fourier series in \(s\) or \(f, \kappa\) in Fourier series' in \(\theta\).}

{\color{red}Or perhaps now we try to apply affine inequalities. Write things in terms of the support function?}
\end{document}
